{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports and initial data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.select_dtypes(include=\"object\").columns :\n",
    "    data[col] = data[col].astype(\"category\")\n",
    "data = data.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "| Feature             | Type               | Description                           | Possible Values / Format                                           | Explanation / Notes                                               |\n",
    "| ------------------- | ------------------ | ------------------------------------- | ------------------------------------------------------------------ | -----------------------------------\n",
    "| `gender`            | Categorical        | Biological sex of the patient         | `Male`, `Female`                                                   | Can be used as a feature; may need encoding for ML models         |\n",
    "| `age`               | Numerical          | Age of the patient in years           | Float                                                              | Important risk factor for stroke; higher age often increases risk |\n",
    "| `hypertension`      | Categorical/Binary | Whether patient has hypertension      | `0` (No), `1` (Yes)                                                | Hypertension is a key stroke risk factor                          |\n",
    "| `heart_disease`     | Categorical/Binary | Whether patient has any heart disease | `0` (No), `1` (Yes)                                                | Another major risk factor for stroke                              |\n",
    "| `ever_married`      | Categorical        | Marital status                        | `Yes`, `No`                                                        | Could correlate with lifestyle or social support                  |\n",
    "| `work_type`         | Categorical        | Type of occupation                    | `Private`, `Self-employed`, `Govt_job`, `Children`, `Never_worked` | Can reflect lifestyle and stress levels                           |\n",
    "| `Residence_type`    | Categorical        | Urban or rural living area            | `Urban`, `Rural`                                                   | Can affect access to healthcare and lifestyle patterns            |\n",
    "| `avg_glucose_level` | Numerical          | Average blood glucose level (mg/dL)   | Float                                                              | High glucose/diabetes increases stroke risk                       |\n",
    "| `bmi`               | Numerical          | Body Mass Index                       | Float (may contain NaN)                                            | Obesity is a risk factor; missing values may need imputation      |\n",
    "| `smoking_status`    | Categorical        | Smoking habits                        | `never smoked`, `formerly smoked`, `smokes`, `Unknown`             | Smoking is a major risk factor; `Unknown` needs special handling  |\n",
    "| `stroke`            | Categorical/Binary | Whether patient has had a stroke      | `0` (No), `1` (Yes)                                                | Target variable for prediction                                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Unvalidated values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### The minimum value of the age column is 0.008 years , which is suspicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of Age\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.hist(data[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"age\"]<=1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### - Upon examining the dataset, the small age values (e.g., 0.08, 0.16, 0.32 years) correspond to children under 1 year old.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Nan Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Data distribution before filling Nan\")\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(data[\"bmi\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Fill Nan with median since the data distribution is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bmi\"] = data[\"bmi\"].fillna(data[\"bmi\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Data distribution after filling Nan\")\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(data[\"bmi\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of duplicated rows: \", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.drop(columns=[\"stroke\"]).select_dtypes(\"number\").columns:\n",
    "    plt.figure()  \n",
    "    plt.title(f\"Data distribution of {col}\")\n",
    "    plt.hist(data[col])  \n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.drop(columns=[\"hypertension\", \"heart_disease\", \"stroke\"]).select_dtypes(include=\"number\").columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))  \n",
    "    plt.title(f\"Box plot of {col}\")\n",
    "    plt.boxplot(data[col])\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Although there are some outliers in bmi and avg_glucose_level, I will primarily use tree-based models (e.g., Random Forest, XGBoost, CatBoost), which are naturally robust to outliers. Therefore, these extreme values will be retained, as they may carry important information for predicting stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Data Cleaning Based on Counterfactual Analysis\n",
    "\n",
    "Upon examining the dataset and generated counterfactuals, we identified **two types of clinically implausible cases**:\n",
    "\n",
    "1. **Extremely low glucose levels** – Some counterfactuals suggested that lowering glucose would increase stroke risk. This is **not supported by medical evidence** and occurs only in a small subset of patients (rare outliers).  \n",
    "\n",
    "2. **Extremely high BMI values (≥ 50)** – A few instances indicated that very high BMI decreases stroke risk, which is **clinically unrealistic** and also represents a small portion of the dataset.  \n",
    "\n",
    "Given that these cases are rare and potentially misleading, it is reasonable to remove them to **improve the plausibility and reliability** of subsequent analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where avg_glucose_level <= 70 AND stroke == 1\n",
    "data = data[~((data['avg_glucose_level'] <= 70) & (data['stroke'] == 1))]\n",
    "data = data[~(data['bmi'] >= 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Imbalanced target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Data distribution of stroke\")\n",
    "plt.hist(data[\"stroke\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### - So the target value is highly imbalanced. I will using SMOTE to oversampling the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(\"number\").corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Building model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mappings = {}\n",
    "dataForModel = data.copy()\n",
    "for col in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:\n",
    "    dataForModel[col] = dataForModel[col].astype('category')\n",
    "    category_mappings[col] = dict(enumerate(dataForModel[col].cat.categories))\n",
    "    dataForModel[col] = dataForModel[col].cat.codes\n",
    "\n",
    "X = dataForModel.drop(columns=\"stroke\")\n",
    "y = dataForModel[\"stroke\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "plt.hist(y_train_res)\n",
    "plt.title(\"Target classes after using SMOTE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Function to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_proba))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sn.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt=\"d\", \n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Predicted No Stroke\", \"Predicted Stroke\"],\n",
    "        yticklabels=[\"Actual No Stroke\", \"Actual Stroke\"]\n",
    "    )\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Tunning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],      # number of trees\n",
    "    'max_depth': [None, 5, 10, 20],      # max depth of tree\n",
    "    'min_samples_split': [2, 5, 10],     # min samples to split\n",
    "    'min_samples_leaf': [1, 2, 4],       # min samples per leaf\n",
    "    'class_weight': ['balanced', {0:1,1:5}, {0:1,1:10}]  # emphasize minority\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',  # maximize recall for minority class\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best recall score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_proba_rf = best_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"===== Random Forest (Grid Search) =====\")\n",
    "evaluate_model(y_test, y_pred_rf, y_proba_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Using tunned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight={0: 1, 1: 2},  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "print(\"===== Random Forest =====\")\n",
    "evaluate_model(y_test, y_pred_rf, y_proba_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X_train_res.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values(by='importance', ascending=True)  # ascending for horizontal bar\n",
    "\n",
    "# Plot horizontal bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_importances['feature'], feature_importances['importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = (y_train==0).sum() / (y_train==1).sum()  # original ratio\n",
    "scale_pos_weight_tuned = scale_pos_weight * 1.5  # increase weight for minority\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    n_estimators=1000,\n",
    "    scale_pos_weight=scale_pos_weight_tuned,  # incresing weight for minority class\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_proba_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"===== XGBoost =====\")\n",
    "evaluate_model(y_test, y_pred_xgb, y_proba_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = (y_train==0).sum() / (y_train==1).sum()  # original ratio\n",
    "scale_pos_weight_tuned = scale_pos_weight * 1.5  # increase weight for minority\n",
    "categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "# Prepare Pool object for CatBoost (categorical features are indexed)\n",
    "cat_features_indices = [X_train_res.columns.get_loc(c) for c in categorical_cols]\n",
    "\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    eval_metric='Recall',\n",
    "    scale_pos_weight=scale_pos_weight_tuned,# incresing weight for minority class\n",
    "    random_state=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "catboost_model.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    cat_features=cat_features_indices\n",
    ")\n",
    "\n",
    "y_pred = catboost_model.predict(X_test)\n",
    "y_proba = catboost_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(\"----Catboost-------\")\n",
    "evaluate_model(y_test, y_pred, y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### We observed that after removing those outliers(avg_glucose_level <=70 but stroke = 1) , we can we that our recall increase significantly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### In conclusion, for healthcare applications, recall is prioritized over precision because false negatives are far more dangerous than false positives. Accepting lower precision is justified in order to ensure that critical cases are not missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Explainable Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_maps = {\n",
    "    'gender': {0: 'Female', 1: 'Male', 2: 'Other'},\n",
    "    'ever_married': {0: 'No', 1: 'Yes'},\n",
    "    'work_type': {0: 'Govt_job', 1: 'Never_worked', 2: 'Private', 3: 'Self-employed', 4: 'children'},\n",
    "    'Residence_type': {0: 'Rural', 1: 'Urban'},\n",
    "    'smoking_status': {0: 'Unknown', 1: 'formerly smoked', 2: 'never smoked', 3: 'smokes'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map the catetory to human-readable\n",
    "def transformCategory(df):\n",
    "    df_copy = df.copy()  # avoid modifying original\n",
    "    for col, mapping in categorical_maps.items():\n",
    "        if col in df_copy.columns:  \n",
    "            df_copy[col] = df_copy[col].map(mapping)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "\n",
    "d = dice_ml.Data(dataframe=X_train_res.assign(target=y_train_res),\n",
    "                  continuous_features=['age', 'avg_glucose_level', \"bmi\"],  \n",
    "                  outcome_name='target')  \n",
    "\n",
    "m = dice_ml.Model(model=rf, backend='sklearn')  \n",
    "exp = dice_ml.Dice(d, m, method='random')  \n",
    "\n",
    "# 4. Generate counterfactuals\n",
    "query_instance = X_test.iloc[4:5]  # can change this \n",
    "cf = exp.generate_counterfactuals(query_instance, total_CFs=3, desired_class=\"opposite\")\n",
    "cf_df = cf.cf_examples_list[0].final_cfs_df  \n",
    "\n",
    "transformCategory(cf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = rf.predict(query_instance)  \n",
    "query_instance.loc[:, \"target\"] = predicted_target\n",
    "transformCategory(query_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformCategory(cf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "## Counterfactual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## 1/\n",
    "\n",
    "We analyzed counterfactuals for a patient profile:\n",
    "\n",
    "| Gender | Age | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|-----|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Female | 43  | No           | No            | Yes     | Private   | Urban     | 86.67       | 33.3 | never smoked   | 0      |\n",
    "\n",
    "The model-generated counterfactuals for this patient are:\n",
    "\n",
    "| Gender | Age | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|-----|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Female | 43  | 0            | 0             | Yes     | Private   | Urban     | 110.87      | 33.3 | formerly smoked | 1      |\n",
    "| Female | 43  | 0            | 0             | Yes     | Private   | Urban     | 69.48       | 33.3 | never smoked   | 1      |\n",
    "| Female | 43  | 0            | 0             | Yes     | Private   | Urban     | 60.55       | 33.3 | never smoked   | 1      |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **Target change:** All counterfactuals flip the predicted stroke from 0 → 1.  \n",
    "2. **Feature changes:** Only the **average glucose level** and **smoking status** vary significantly.  \n",
    "3. **Unrealistic pattern:**  \n",
    "   - Two counterfactuals suggest that **lowering average glucose level (69.48, 60.55)** increases stroke risk.  \n",
    "   - This is **not clinically plausible**, as lower glucose does not increase stroke probability.  \n",
    "\n",
    "### Actionable insight\n",
    "\n",
    "- This highlights that the model may have learned **spurious relationships** from rare cases.  \n",
    "- To generate **meaningful and medically realistic counterfactuals**, extreme or low-probability feature values should be filtered out during analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['stroke'][(data[\"avg_glucose_level\"]<=70) & (data['stroke'] == 1)].count() / data['stroke'][(data[\"avg_glucose_level\"]<=70) & (data['stroke'] == 0)].count() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### Go deeper we can see that the case that the patient has **avg_glucose_level <= 70** and has stroke is only **3,7%**. So for more reasonable analysis, we should consider those as outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## 2/\n",
    "\n",
    "We examined counterfactuals for the following patient profile:\n",
    "\n",
    "| Gender | Age | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|-----|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Male   | 17  | No           | No            | No      | Govt_job  | Urban     | 68.91       | 23.0 | Unknown        | 0      |\n",
    "\n",
    "After removing extreme or unrealistic outliers (e.g., extremely low or high glucose levels), the model-generated counterfactuals are:\n",
    "\n",
    "| Gender | Age  | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|------|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Male   | 76.6 | 0            | 0             | No      | Govt_job  | Urban     | 222.16      | 23.0 | Unknown        | 1      |\n",
    "| Male   | 57.1 | 0            | 0             | No      | Govt_job  | Urban     | 179.49      | 23.0 | Unknown        | 1      |\n",
    "| Male   | 65.8 | 0            | 0             | No      | Govt_job  | Urban     | 227.21      | 23.0 | Unknown        | 1      |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **Target change:** All counterfactuals flip the predicted stroke from 0 → 1.  \n",
    "2. **Feature changes:** The primary changes are in **age** and **average glucose level**, which increase in the CFs.  \n",
    "3. **Reasonable pattern:**  \n",
    "   - Older age and higher glucose levels are associated with increased stroke risk.  \n",
    "   - This aligns with clinical expectations and literature.  \n",
    "\n",
    "### Actionable insight\n",
    "\n",
    "- By removing outliers from the dataset, the counterfactuals now reflect **plausible and medically meaningful scenarios**.  \n",
    "- This demonstrates that careful preprocessing (outlier removal) is essential for **trustworthy counterfactual explanations** in healthcare models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## 3/\n",
    "\n",
    "Original patient profile:\n",
    "\n",
    "| Gender | Age | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|-----|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Female | 5   | No           | No            | No      | children  | Rural     | 102.04      | 18.5 | Unknown        | 0      |\n",
    "\n",
    "Counterfactuals generated:\n",
    "\n",
    "| Gender | Age  | Hypertension | Heart Disease | Married | Work Type   | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|------|--------------|---------------|---------|------------|-----------|-------------|------|----------------|--------|\n",
    "| Female | 49.9 | 0            | 0             | No      | Private    | Rural     | 102.04      | 18.5 | Unknown        | 1      |\n",
    "| Female | 74.4 | 0            | 0             | No      | Never_worked | Rural   | 102.04      | 18.5 | Unknown        | 1      |\n",
    "| Female | 76.3 | 0            | 0             | No      | Govt_job   | Rural     | 102.04      | 18.5 | Unknown        | 1      |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **Target change:** All counterfactuals flip stroke prediction from 0 → 1.  \n",
    "2. **Feature changes:** The main changes are **age** and **work type**, while glucose and BMI remain constant.  \n",
    "3. **Insight:**  \n",
    "   - Even at low BMI and normal glucose levels, older age and occupational stress factors (work type) increase predicted stroke risk.  \n",
    "   - This suggests that **stress-related factors might be important contributors** to stroke risk in the model.  \n",
    "\n",
    "### Actionable insight\n",
    "\n",
    "- Counterfactual analysis highlights that **non-traditional risk factors** such as age-related stress and occupational exposure can strongly influence predicted stroke risk.  \n",
    "- Proper handling of stress and lifestyle factors is crucial, especially for individuals in high-risk age groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## 4/\n",
    "\n",
    "**Original patient profile:**  \n",
    "\n",
    "| Gender | Age  | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI  | Smoking Status | Target |\n",
    "|--------|------|--------------|---------------|---------|-----------|-----------|-------------|------|----------------|--------|\n",
    "| Male   | 61.0 | 1            | 1             | Yes     | Govt_job  | Rural     | 86.06       | 34.8 | never smoked   | 1      |\n",
    "\n",
    "**Counterfactuals generated:**  \n",
    "\n",
    "| Gender | Age  | Hypertension | Heart Disease | Married | Work Type | Residence | Avg Glucose | BMI   | Smoking Status | Target |\n",
    "|--------|------|--------------|---------------|---------|-----------|-----------|-------------|-------|----------------|--------|\n",
    "| Male   | 61.0 | 1            | 1             | Yes     | children  | Rural     | 86.06       | 96.1  | never smoked   | 0      |\n",
    "| Male   | 32.9 | 1            | 1             | Yes     | Govt_job  | Rural     | 86.06       | 34.8  | never smoked   | 0      |\n",
    "| Male   | 61.0 | 1            | 1             | Yes     | Govt_job  | Rural     | 67.00       | 34.8  | never smoked   | 0      |\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "1. **Target change:** All counterfactuals flip stroke prediction from 1 → 0.  \n",
    "2. **Feature changes and plausibility:**  \n",
    "   - The most notable change is **BMI = 96.1** in one counterfactual, which is **clinically implausible**.  \n",
    "3. **Insight:**  \n",
    "   - The model appears **overly sensitive to extreme BMI increases**, which can artificially reduce predicted stroke risk.  \n",
    "   \n",
    "### Actionable insight\n",
    "\n",
    "- Counterfactual analysis reveals that **extreme BMI changes dominate the model’s predictions**, but these are **not realistic**.  \n",
    "- For meaningful interpretation, **filtering out implausible counterfactuals** is necessary.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['bmi']>=50) & (data['stroke']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['bmi']>=50) & (data['stroke']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "#### Upon examining the dataset and generated counterfactuals, we observed several instances with **extremely high BMI values (≥ 50)** that produce unrealistic or implausible predictions. Due to the dataset's high class imbalance, although higher BMI should generally increase stroke risk, the majority of these high-BMI instances have **stroke = 0**, which skews the model’s behavior. These instances can be considered **outliers**, and since they represent a small portion of the data, it is reasonable to remove them to improve the plausibility and reliability of subsequent analyses.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
